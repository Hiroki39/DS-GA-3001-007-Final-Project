{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "忽略Keras RL的部分。Stable-baselines在下面  \n",
    "这个现在用的是gym 0.26.2, 在monitor.py里有一个return的问题可能需要更改return的value数量才能兼容  \n",
    "PPO感觉挺好的，在只120步的时候可以超过random选择的return。DQN在训练120步的时候不行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras RL DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///gpfs/data/oermannlab/users/hz2212/DS-GA%203001-007/disneyenv\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: disneyenv\n",
      "  Attempting uninstall: disneyenv\n",
      "    Found existing installation: disneyenv 0.0.1\n",
      "    Uninstalling disneyenv-0.0.1:\n",
      "      Successfully uninstalled disneyenv-0.0.1\n",
      "  Running setup.py develop for disneyenv\n",
      "Successfully installed disneyenv-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e disneyenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/hz2212/DS-GA 3001-007/disneyenv/disneyenv/envs/disney.py:42: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.waittime = pd.read_csv(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "action space does not inherit from `gymnasium.spaces.Space`, actual type: <class 'gym.spaces.discrete.Discrete'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdisneyenv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisneyenv/Disney-v0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ds3001-007/lib/python3.10/site-packages/gymnasium/envs/registration.py:669\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# Run the environment checker as the lowest level wrapper\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_env_checker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    667\u001b[0m     disable_env_checker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m spec_\u001b[38;5;241m.\u001b[39mdisable_env_checker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m ):\n\u001b[0;32m--> 669\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mPassiveEnvChecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Add the order enforcing wrapper\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_\u001b[38;5;241m.\u001b[39morder_enforce:\n",
      "File \u001b[0;32m~/.conda/envs/ds3001-007/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:23\u001b[0m, in \u001b[0;36mPassiveEnvChecker.__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(env)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m     21\u001b[0m     env, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment must specify an action space. https://gymnasium.farama.org/content/environment_creation/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mcheck_action_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m     25\u001b[0m     env, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation_space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment must specify an observation space. https://gymnasium.farama.org/content/environment_creation/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m check_observation_space(env\u001b[38;5;241m.\u001b[39mobservation_space)\n",
      "File \u001b[0;32m~/.conda/envs/ds3001-007/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:74\u001b[0m, in \u001b[0;36mcheck_space\u001b[0;34m(space, space_type, check_box_space_fn)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"A passive check of the environment action space that should not affect the environment.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(space, spaces\u001b[38;5;241m.\u001b[39mSpace):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspace_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m space does not inherit from `gymnasium.spaces.Space`, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(space)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m     79\u001b[0m     check_box_space_fn(space)\n",
      "\u001b[0;31mAssertionError\u001b[0m: action space does not inherit from `gymnasium.spaces.Space`, actual type: <class 'gym.spaces.discrete.Discrete'>"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import disneyenv\n",
    "\n",
    "env = gym.make('disneyenv/Disney-v0') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,Input,Dropout,Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Dense(512,activation=\"relu\",input_shape = (1,input_shape)),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(256,activation = \"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(128,activation = \"relu\"),\n",
    "        Dense(64,activation = \"relu\"),\n",
    "        Dense(output_shape,activation = \"linear\"),\n",
    "        Flatten()\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
    "    memory = SequentialMemory(limit=2000,window_length = 1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  enable_dueling_network=True, dueling_type='avg',\n",
    "                  nb_actions=actions, nb_steps_warmup=10)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 512)            118784    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 512)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 106)               6890      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 106)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,154\n",
      "Trainable params: 298,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(env.observation_space.n,env.action_space.n)\n",
    "dqn_agent = build_agent(model,env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_agent.compile(Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gymnasium versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gymnasium versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new day! Today is 2018-7-26\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/10000 [..............................] - ETA: 1:21:38 - reward: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11/10000 [..............................] - ETA: 46:40 - reward: -35.2727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82751\\anaconda3\\envs\\my_environment\\lib\\site-packages\\rl\\memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72/10000 [..............................] - ETA: 55:26 - reward: -33.9792A new day! Today is 2017-7-24\n",
      "  119/10000 [..............................] - ETA: 54:14 - reward: -27.1176A new day! Today is 2017-10-23\n",
      "  191/10000 [..............................] - ETA: 53:18 - reward: -30.8901A new day! Today is 2018-4-12\n",
      "  253/10000 [..............................] - ETA: 52:33 - reward: -30.8043A new day! Today is 2018-6-22\n",
      "  307/10000 [..............................] - ETA: 52:05 - reward: -29.1824A new day! Today is 2018-6-20\n",
      "  358/10000 [>.............................] - ETA: 51:42 - reward: -29.3142A new day! Today is 2017-8-6\n",
      "  400/10000 [>.............................] - ETA: 51:25 - reward: -28.6212A new day! Today is 2018-6-28\n",
      "  449/10000 [>.............................] - ETA: 51:04 - reward: -28.3864A new day! Today is 2018-9-12\n",
      "  517/10000 [>.............................] - ETA: 50:21 - reward: -28.9052A new day! Today is 2018-8-21\n",
      "  564/10000 [>.............................] - ETA: 50:03 - reward: -28.6835A new day! Today is 2017-12-26\n",
      "  620/10000 [>.............................] - ETA: 49:50 - reward: -27.9808A new day! Today is 2018-1-4\n",
      "  657/10000 [>.............................] - ETA: 49:42 - reward: -27.4909A new day! Today is 2018-8-20\n",
      "  712/10000 [=>............................] - ETA: 52:03 - reward: -27.5822A new day! Today is 2017-11-24\n",
      "  764/10000 [=>............................] - ETA: 51:18 - reward: -27.3043A new day! Today is 2018-1-9\n",
      "  852/10000 [=>............................] - ETA: 50:37 - reward: -28.6092A new day! Today is 2018-8-7\n",
      "  906/10000 [=>............................] - ETA: 50:10 - reward: -28.6987A new day! Today is 2017-9-15\n",
      "  978/10000 [=>............................] - ETA: 49:39 - reward: -29.1131A new day! Today is 2018-9-14\n",
      " 1000/10000 [==>...........................] - ETA: 49:28 - reward: -29.2526done, took 330.622 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27c2d54e850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_agent.fit(env, nb_steps = 1000, visualize = False, verbose = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Baseline3 DQN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///gpfs/data/oermannlab/users/hz2212/DS-GA%203001-007/disneyenv\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: disneyenv\n",
      "  Attempting uninstall: disneyenv\n",
      "    Found existing installation: disneyenv 0.0.1\n",
      "    Uninstalling disneyenv-0.0.1:\n",
      "      Successfully uninstalled disneyenv-0.0.1\n",
      "  Running setup.py develop for disneyenv\n",
      "Successfully installed disneyenv-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e disneyenv\n",
    "import disneyenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3 import PPO, DQN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "A new day! Today is 2017-06-28\n",
      "34 4.28935758196377 0 0\n",
      "53 4.28935758196377 0 0\n",
      "28 4.28935758196377 0 0\n",
      "99 10.98346366328823 0 0\n",
      "97 1 0 0\n",
      "26 3.9159537738724377 10.0 1.33\n",
      "75 19.59417004116794 0 0\n",
      "28 6.952561299901862 5.0 1.7\n",
      "57 4.28935758196377 0.0 15.0\n",
      "3 4.427468568945695 90.0 6.0\n",
      "0 1 0.0 23.0\n",
      "37 8.475478910832758 15.0 9.5\n",
      "73 6.952561299901862 0.0 1.0\n",
      "25 8.915803968707229 0 0\n",
      "24 1 0 0\n",
      "56 3.1860278534694153 0 0\n",
      "28 4.28935758196377 50.0 1.7\n",
      "14 2.840482247690528 50.0 2.25\n",
      "28 2.840482247690528 50.0 1.7\n",
      "3 8.475478910832758 90.0 6.0\n",
      "93 3.2092080495726365 120.0 6.0\n",
      "99 1 0 0\n",
      "66 8.47101437623175 0.0 9.0\n",
      "36 2.8928096074512313 25.0 2.5\n",
      "52 4.989969523972208 15.0 4.0\n",
      "81 8.525921822877574 70.0 8.0\n",
      "56 8.589987861357613 0 0\n",
      "31 4.28935758196377 0 0\n",
      "62 4.28935758196377 0 0\n",
      "100 3.644003512864643 0.0 11.0\n",
      "64 5.441703570715497 60.0 3.0\n",
      "The day is over! The reward is 123.26499458149094\n",
      "A new day! Today is 2017-07-13\n",
      "8 4.427468568945695 0 0\n",
      "72 15.273673239199109 0 0\n",
      "62 11.239250545678996 0 0\n",
      "102 4.007803450589587 0 0\n",
      "59 4.007803450589587 0.0 16.0\n",
      "33 4.28935758196377 30.0 3.0\n",
      "78 11.95665705905574 5.0 1.0\n",
      "71 18.35710511374767 0.0 10.0\n",
      "99 17.923516599263525 0 0\n",
      "57 6.697664654779026 0.0 15.0\n",
      "2 4.427468568945695 0 0\n",
      "98 3.2092080495726365 0 0\n",
      "11 9.206277510904412 15.0 4.5\n",
      "103 0 10 0\n",
      "102 5.735536320412861 0 0\n",
      "77 8.067995285858656 5.0 2.5\n",
      "40 11.95665705905574 0.0 10.0\n",
      "20 2.520433276982838 25.0 3.5\n",
      "60 3.1860278534694153 0.0 7.0\n",
      "36 4.28935758196377 20.0 2.5\n",
      "34 1 15.0 3.0\n",
      "94 10.98346366328823 5.0 2.0\n",
      "0 3.2092080495726365 0.0 23.0\n",
      "68 15.273673239199109 5.0 1.0\n",
      "84 18.35710511374767 30.0 1.5\n",
      "84 1 20.0 1.5\n",
      "60 8.589987861357613 0 0\n",
      "54 1 0 0\n",
      "7 4.427468568945695 0 0\n",
      "98 3.2092080495726365 0 0\n",
      "65 8.47101437623175 25.0 7.5\n",
      "34 2.8928096074512313 15.0 3.0\n",
      "60 4.28935758196377 0 0\n",
      "50 5.2531079862843475 0 0\n",
      "97 10.42061399316902 0 0\n",
      "92 1.4049969637256643 0.0 9.0\n",
      "51 9.776251235425471 75.0 11.0\n",
      "89 2.2521567389083414 15.0 9.0\n",
      "46 6.682006538126892 30.0 5.0\n",
      "89 6.682006538126892 30.0 9.0\n",
      "5 6.982232655600034 0 0\n",
      "94 3.2092080495726365 15.0 2.0\n",
      "69 17.923516599263525 5.0 1.5\n",
      "59 11.239250545678996 0.0 16.0\n",
      "82 8.589987861357613 0 0\n",
      "50 8.525921822877574 0 0\n",
      "The day is over! The reward is 231.7576184589574\n",
      "A new day! Today is 2018-04-06\n",
      "44 6.748117384482564 0 0\n",
      "17 4.773058359766563 0 0\n",
      "100 6.308809166467449 15.0 11.0\n",
      "94 3.0552787561825614 15.0 2.0\n",
      "75 17.923516599263525 0 0\n",
      "47 4.491214084073219 0 0\n",
      "60 6.748117384482564 0.0 7.0\n",
      "24 3.1860278534694153 0 0\n",
      "1 7.5923188645377415 5.0 5.0\n",
      "37 8.475478910832758 15.0 9.5\n",
      "76 11.95665705905574 0 0\n",
      "3 8.471107496160963 100.0 6.0\n",
      "32 8.475478910832758 20.0 2.0\n",
      "30 1 10.0 1.5\n",
      "59 4.28935758196377 0.0 16.0\n",
      "82 8.589987861357613 15.0 2.0\n",
      "89 7.5295996928419155 35.0 9.0\n",
      "30 4.544168001735182 20.0 1.5\n",
      "22 2.520433276982838 5.0 14.0\n",
      "98 9.535217852583342 0 0\n",
      "96 1 0 0\n",
      "86 3.147782119747535 85.0 7.0\n",
      "42 11.99149167799481 0.0 10.0\n",
      "26 15.18102084284551 0 0\n",
      "86 3.2075464522953623 20.0 7.0\n",
      "52 7.802225504507815 5.0 4.0\n",
      "49 6.472569343161453 0 0\n",
      "92 13.439762709347965 0.0 9.0\n",
      "20 9.25782967752384 50.0 3.5\n",
      "78 9.561408510377229 5.0 1.0\n",
      "80 1 0 0\n",
      "51 8.525921822877574 0 0\n",
      "90 2.2521567389083414 10.0 15.0\n",
      "20 2.053023649280206 35.0 3.5\n",
      "90 2.053023649280206 10.0 15.0\n",
      "45 6.682006538126892 0 0\n",
      "8 10.839894901576656 0 0\n",
      "41 8.475478910832758 0 0\n",
      "78 11.95665705905574 0 0\n",
      "The day is over! The reward is 172.88862547951874\n",
      "A new day! Today is 2018-04-15\n",
      "59 1 0 0\n",
      "3 4.427468568945695 5.0 6.0\n",
      "46 10.839894901576656 0 0\n",
      "20 4.643009155441806 0 0\n",
      "100 6.535380169425697 0.0 11.0\n",
      "42 10.387442356192368 0 0\n",
      "3 10.839894901576656 15.0 6.0\n",
      "51 9.234386578672103 5.0 11.0\n",
      "82 8.525921822877574 5.0 2.0\n",
      "61 8.589987861357613 0.0 15.0\n",
      "82 8.589987861357613 5.0 2.0\n",
      "34 11.95665705905574 10.0 3.0\n",
      "64 2.8928096074512313 40.0 3.0\n",
      "79 9.096194096291342 0 0\n",
      "23 9.561408510377229 0.0 45.0\n",
      "64 1.166371674414502 40.0 3.0\n",
      "98 8.47101437623175 0 0\n",
      "12 9.206277510904412 10.0 15.0\n",
      "48 4.773058359766563 30.0 4.0\n",
      "37 2.464349992427426 25.0 9.5\n",
      "57 4.28935758196377 0.0 15.0\n",
      "96 6.697664654779026 0 0\n",
      "5 3.2092080495726365 0.0 11.0\n",
      "22 7.5923188645377415 0.0 14.0\n",
      "44 4.643009155441806 15.0 0.73\n",
      "88 11.99149167799481 55.0 4.5\n",
      "46 11.99149167799481 15.0 5.0\n",
      "35 2.464349992427426 0.0 15.0\n",
      "43 2.464349992427426 0.0 5.0\n",
      "66 5.283685436233072 0.0 9.0\n",
      "102 2.4500430586758966 0.0 60.0\n",
      "22 1.9652478523783328 0 0\n",
      "63 1.166371674414502 10.0 14.5\n",
      "3 6.432100735836362 45.0 6.0\n",
      "22 7.5923188645377415 0 0\n",
      "20 1 30.0 3.5\n",
      "25 1 0.0 25.0\n",
      "The day is over! The reward is 232.45654753664405\n",
      "A new day! Today is 2017-07-03\n",
      "2 4.427468568945695 0 0\n",
      "97 3.2092080495726365 0 0\n",
      "51 10.42061399316902 0 0\n",
      "47 6.472569343161453 0 0\n",
      "87 11.99149167799481 0 0\n",
      "92 2.0672471411300837 0.0 9.0\n",
      "74 17.922491940328996 0 0\n",
      "34 6.952561299901862 5.0 3.0\n",
      "4 8.475478910832758 5.0 17.0\n",
      "49 10.839894901576656 0 0\n",
      "80 14.204159686663917 20.0 9.0\n",
      "16 11.721669118593923 0.0 45.0\n",
      "40 2.840482247690528 0 0\n",
      "45 2.464349992427426 0.0 5.0\n",
      "23 4.643009155441806 5.0 45.0\n",
      "30 2.520433276982838 15.0 1.5\n",
      "96 10.98346366328823 0 0\n",
      "84 6.6196616796660415 50.0 1.5\n",
      "63 9.096194096291342 10.0 14.5\n",
      "33 2.8928096074512313 35.0 3.0\n",
      "100 7.932349138577956 0.0 11.0\n",
      "11 6.308809166467449 35.0 4.5\n",
      "93 9.206277510904412 135.0 6.0\n",
      "59 6.697664654779026 0.0 16.0\n",
      "6 4.427468568945695 0 0\n",
      "29 8.475478910832758 10.0 3.0\n",
      "37 1 0 0\n",
      "34 1 20.0 3.0\n",
      "91 4.544168001735182 0 0\n",
      "19 5.304757208164739 0 0\n",
      "51 6.721843365567614 60.0 11.0\n",
      "53 5.2531079862843475 0 0\n",
      "9 3.1404184535094077 15.0 1.5\n",
      "83 11.721669118593923 5.0 7.0\n",
      "8 8.471107496160963 0 0\n",
      "81 8.471107496160963 0 0\n",
      "31 11.95665705905574 75.0 2.0\n",
      "85 11.95665705905574 0.0 24.0\n",
      "5 8.471107496160963 0 0\n",
      "33 8.475478910832758 0 0\n",
      "34 1 0 0\n",
      "55 4.28935758196377 0 0\n",
      "55 1 0 0\n",
      "102 4.007803450589587 0 0\n",
      "77 8.067995285858656 0 0\n",
      "86 4.039609388161948 0 0\n",
      "85 4.039609388161948 0.0 24.0\n",
      "80 1 0 0\n",
      "42 14.204159686663917 0 0\n",
      "78 14.204159686663917 0 0\n",
      "92 5.22018453893626 0 0\n",
      "71 17.922491940328996 0 0\n",
      "103 0 10 0\n",
      "37 6.952561299901862 0 0\n",
      "4 8.475478910832758 0 0\n",
      "60 4.427468568945695 0 0\n",
      "98 6.697664654779026 0 0\n",
      "59 6.697664654779026 0 0\n",
      "3 4.427468568945695 0 0\n",
      "71 15.273673239199109 0 0\n",
      "4 15.273673239199109 0 0\n",
      "13 6.29793434442699 0 0\n",
      "70 9.05524889913785 0 0\n",
      "62 11.239250545678996 0 0\n",
      "1 4.427468568945695 0 0\n",
      "13 6.29793434442699 0 0\n",
      "60 3.1404184535094077 0 0\n",
      "80 8.589987861357613 0 0\n",
      "44 14.204159686663917 0 0\n",
      "63 5.283685436233072 0 0\n",
      "18 3.327583925554344 0 0\n",
      "66 3.327583925554344 0 0\n",
      "61 2.0196961183755557 0 0\n",
      "61 1 0 0\n",
      "58 1 0 0\n",
      "4 4.427468568945695 0 0\n",
      "18 6.29793434442699 0 0\n",
      "18 1 0 0\n",
      "43 4.773058359766563 0 0\n",
      "31 2.464349992427426 0 0\n",
      "70 6.952561299901862 0 0\n",
      "32 6.952561299901862 0 0\n",
      "61 4.28935758196377 0 0\n",
      "15 3.1404184535094077 0 0\n",
      "101 6.308809166467449 0 0\n",
      "17 6.308809166467449 0 0\n",
      "70 9.05524889913785 0 0\n",
      "50 10.07768623029082 0 0\n",
      "56 5.2531079862843475 0 0\n",
      "49 6.748117384482564 0 0\n",
      "41 2.464349992427426 0 0\n",
      "96 10.98346366328823 0 0\n",
      "86 3.147782119747535 0 0\n",
      "87 1 0 0\n",
      "34 9.55163482673063 0 0\n",
      "92 10.975550898394856 0 0\n",
      "87 2.0672471411300837 0 0\n",
      "80 4.039609388161948 0 0\n",
      "62 8.589987861357613 0 0\n",
      "54 1 0 0\n",
      "86 5.48579248412074 0 0\n",
      "12 8.541454733661212 5.0 15.0\n",
      "55 3.1404184535094077 0 0\n",
      "35 4.28935758196377 0 0\n",
      "67 6.952561299901862 5.0 1.5\n",
      "16 9.05524889913785 0 0\n",
      "71 9.05524889913785 0.0 10.0\n",
      "34 6.952561299901862 10.0 3.0\n",
      "20 2.520433276982838 15.0 3.5\n",
      "82 9.561408510377229 5.0 2.0\n",
      "0 8.471107496160963 0.0 23.0\n",
      "76 8.471107496160963 0.0 1.0\n",
      "90 7.5295996928419155 5.0 15.0\n",
      "87 5.921946812081614 0.0 20.0\n",
      "53 5.48579248412074 0 0\n",
      "4 4.427468568945695 5.0 17.0\n",
      "86 4.431505114011317 40.0 7.0\n",
      "7 4.431505114011317 0 0\n",
      "101 1.9192867931509592 0.0 11.0\n",
      "90 5.5167305198417225 20.0 15.0\n",
      "60 3.151147998568417 0.0 7.0\n",
      "21 3.1860278534694153 0.0 5.0\n",
      "32 2.520433276982838 25.0 2.0\n",
      "15 2.840482247690528 70.0 7.0\n",
      "16 1 0.0 45.0\n",
      "2 6.29793434442699 0 0\n",
      "95 3.2092080495726365 15.0 1.3\n",
      "55 6.697664654779026 0 0\n",
      "32 4.28935758196377 10.0 2.0\n",
      "12 2.840482247690528 0 0\n",
      "33 2.840482247690528 40.0 3.0\n",
      "63 2.8928096074512313 10.0 14.5\n",
      "69 9.704361340810864 5.0 1.5\n",
      "21 8.915803968707229 0.0 5.0\n",
      "9 3.944879147839698 20.0 1.5\n",
      "59 3.1404184535094077 0.0 16.0\n",
      "49 6.748117384482564 0 0\n",
      "26 15.18102084284551 10.0 1.33\n",
      "27 12.750100901157689 25.0 4.0\n",
      "11 2.840482247690528 5.0 4.5\n",
      "28 2.840482247690528 15.0 1.7\n",
      "11 2.840482247690528 5.0 4.5\n",
      "77 11.721669118593923 5.0 2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 7.5295996928419155 0 0\n",
      "15 5.304757208164739 35.0 7.0\n",
      "The day is over! The reward is 358.80087827857795\n",
      "A new day! Today is 2018-01-24\n",
      "83 8.589987861357613 0 0\n",
      "98 6.6196616796660415 0 0\n",
      "24 9.535217852583342 0 0\n",
      "54 3.1860278534694153 0 0\n",
      "45 6.748117384482564 0 0\n",
      "11 4.773058359766563 0 0\n",
      "69 9.05524889913785 0 0\n",
      "65 9.704361340810864 0 0\n",
      "89 1.9952684778632919 0 0\n",
      "41 4.544168001735182 0 0\n",
      "82 11.95665705905574 0 0\n",
      "54 8.589987861357613 0 0\n",
      "22 3.1860278534694153 0 0\n",
      "2 7.5923188645377415 0 0\n",
      "45 10.839894901576656 0 0\n",
      "41 2.464349992427426 0 0\n",
      "101 7.932349138577956 0 0\n",
      "75 14.878335786181772 0 0\n",
      "44 4.491214084073219 0 0\n",
      "34 2.464349992427426 0 0\n",
      "94 10.98346366328823 10.0 2.0\n",
      "27 10.98346366328823 5.0 4.0\n",
      "10 2.840482247690528 5.0 4.5\n",
      "38 2.840482247690528 0 0\n",
      "28 1 0 0\n",
      "27 1 15.0 4.0\n",
      "85 11.95665705905574 0.0 24.0\n",
      "23 9.561408510377229 5.0 45.0\n",
      "89 2.053023649280206 15.0 9.0\n",
      "33 4.544168001735182 30.0 3.0\n",
      "29 1 10.0 3.0\n",
      "62 4.28935758196377 0 0\n",
      "101 3.644003512864643 0.0 11.0\n",
      "71 14.878335786181772 0.0 10.0\n",
      "65 9.704361340810864 15.0 7.5\n",
      "36 2.8928096074512313 15.0 2.5\n",
      "41 1 0 0\n",
      "8 8.475478910832758 0 0\n",
      "91 6.982232655600034 0 0\n",
      "100 5.5167305198417225 15.0 11.0\n",
      "6 1.9192867931509592 0 0\n",
      "64 6.432100735836362 0 0\n",
      "36 2.8928096074512313 15.0 2.5\n",
      "31 1 90.0 2.0\n",
      "27 1 5.0 4.0\n",
      "94 10.98346366328823 10.0 2.0\n",
      "49 13.434202645384012 0 0\n",
      "9 4.773058359766563 15.0 1.5\n",
      "11 1 5.0 4.5\n",
      "53 3.1404184535094077 5.0 22.0\n",
      "28 4.28935758196377 0 0\n",
      "81 11.95665705905574 30.0 8.0\n",
      "22 9.561408510377229 0 0\n",
      "50 2.786035026166958 0 0\n",
      "86 7.802225504507815 0 0\n",
      "94 3.147782119747535 0 0\n",
      "22 9.535217852583342 0 0\n",
      "76 9.561408510377229 0 0\n",
      "81 1 0 0\n",
      "0 8.471107496160963 0 0\n",
      "0 1 0 0\n",
      "77 8.471107496160963 0 0\n",
      "94 6.6196616796660415 0 0\n",
      "29 10.98346366328823 0 0\n",
      "34 1 0 0\n",
      "The day is over! The reward is 170.1946165039047\n",
      "A new day! Today is 2017-07-28\n",
      "65 2.0196961183755557 0 0\n",
      "46 5.283685436233072 0 0\n",
      "43 1 0 0\n",
      "63 5.283685436233072 0 0\n",
      "66 1 0 0\n",
      "18 3.327583925554344 0 0\n",
      "18 1 0 0\n",
      "95 9.206277510904412 5.0 1.3\n",
      "45 13.434202645384012 0 0\n",
      "60 6.748117384482564 0.0 7.0\n",
      "70 11.239250545678996 5.0 9.0\n",
      "21 8.915803968707229 0.0 5.0\n",
      "8 7.5923188645377415 0 0\n",
      "57 4.427468568945695 0.0 15.0\n",
      "33 4.28935758196377 40.0 3.0\n",
      "74 6.952561299901862 0 0\n",
      "86 16.425478515012056 55.0 7.0\n",
      "97 3.147782119747535 0 0\n",
      "6 3.2092080495726365 0 0\n",
      "53 4.427468568945695 0 0\n",
      "87 5.48579248412074 0.0 20.0\n",
      "85 4.039609388161948 0.0 24.0\n",
      "21 9.561408510377229 0.0 5.0\n",
      "24 1 0 0\n",
      "58 3.1860278534694153 0.0 3.0\n",
      "35 4.28935758196377 0.0 15.0\n",
      "24 2.520433276982838 0 0\n",
      "103 0 10 0\n",
      "1 7.5923188645377415 25.0 5.0\n",
      "45 10.839894901576656 0.0 5.0\n",
      "94 13.434202645384012 10.0 2.0\n",
      "19 9.206277510904412 0 0\n",
      "75 9.05524889913785 0 0\n",
      "24 8.915803968707229 0 0\n",
      "89 2.053023649280206 20.0 9.0\n",
      "5 6.982232655600034 0.0 11.0\n",
      "89 6.982232655600034 20.0 9.0\n",
      "91 1 0 0\n",
      "79 7.5295996928419155 5.0 3.0\n",
      "19 11.721669118593923 0 0\n",
      "79 11.721669118593923 5.0 3.0\n",
      "94 6.6196616796660415 10.0 2.0\n",
      "71 17.923516599263525 0.0 10.0\n",
      "74 1 0 0\n",
      "84 18.35710511374767 15.0 1.5\n",
      "35 11.95665705905574 0.0 15.0\n",
      "42 2.464349992427426 0.0 10.0\n",
      "87 11.99149167799481 0.0 20.0\n",
      "27 9.55163482673063 10.0 4.0\n",
      "21 2.520433276982838 0.0 5.0\n",
      "8 7.5923188645377415 0 0\n",
      "12 6.29793434442699 0 0\n",
      "52 6.721843365567614 5.0 4.0\n",
      "62 5.2531079862843475 0 0\n",
      "16 3.1404184535094077 0 0\n",
      "64 3.327583925554344 45.0 3.0\n",
      "43 5.283685436233072 0 0\n",
      "21 4.643009155441806 0.0 5.0\n",
      "The day is over! The reward is 171.9308498926562\n",
      "A new day! Today is 2017-11-24\n",
      "9 3.1404184535094077 0 0\n",
      "60 3.1404184535094077 0.0 7.0\n",
      "37 4.28935758196377 0 0\n",
      "12 2.840482247690528 0 0\n",
      "10 1 0 0\n",
      "35 2.840482247690528 0.0 15.0\n",
      "41 1 0 0\n",
      "78 11.95665705905574 5.0 1.0\n",
      "103 0 10 0\n",
      "81 1 55.0 8.0\n",
      "84 1 0 0\n",
      "80 1 15.0 9.0\n",
      "73 18.35710511374767 0.0 1.0\n",
      "8 15.273673239199109 0 0\n",
      "71 15.273673239199109 0.0 10.0\n",
      "63 9.704361340810864 10.0 14.5\n",
      "89 1.9952684778632919 80.0 9.0\n",
      "80 7.5295996928419155 30.0 9.0\n",
      "77 1 0 0\n",
      "77 1 5.0 2.5\n",
      "62 8.589987861357613 0 0\n",
      "51 5.2531079862843475 110.0 11.0\n",
      "43 6.472569343161453 0.0 5.0\n",
      "40 2.464349992427426 0.0 10.0\n",
      "12 2.840482247690528 5.0 15.0\n",
      "22 3.944879147839698 0.0 14.0\n",
      "18 3.944879147839698 0.0 15.0\n",
      "26 11.698628738018572 20.0 1.33\n",
      "103 0 10 0\n",
      "40 12.750100901157689 0.0 10.0\n",
      "57 4.28935758196377 0.0 15.0\n",
      "30 4.28935758196377 15.0 1.5\n",
      "47 2.464349992427426 0.0 5.0\n",
      "53 6.748117384482564 25.0 22.0\n",
      "101 3.644003512864643 0.0 11.0\n",
      "23 6.535380169425697 0 0\n",
      "27 2.520433276982838 10.0 4.0\n",
      "98 10.98346366328823 0 0\n",
      "103 0 10 0\n",
      "25 9.535217852583342 0.0 25.0\n",
      "30 2.520433276982838 15.0 1.5\n",
      "63 2.8928096074512313 10.0 14.5\n",
      "The day is over! The reward is 223.22765935867247\n",
      "A new day! Today is 2018-03-13\n",
      "44 6.748117384482564 0 0\n",
      "7 10.839894901576656 0 0\n",
      "54 4.427468568945695 0 0\n",
      "6 4.427468568945695 0 0\n",
      "49 10.839894901576656 0 0\n",
      "5 10.839894901576656 0 0\n",
      "87 4.431505114011317 0.0 20.0\n",
      "95 3.147782119747535 15.0 1.3\n",
      "89 8.298973953604898 5.0 9.0\n",
      "41 4.544168001735182 0 0\n",
      "6 8.475478910832758 0 0\n",
      "73 15.273673239199109 0 0\n",
      "22 8.915803968707229 0.0 14.0\n",
      "3 7.5923188645377415 45.0 6.0\n",
      "27 8.475478910832758 25.0 4.0\n",
      "2 8.475478910832758 0.0 30.0\n",
      "61 4.427468568945695 0.0 15.0\n",
      "19 3.1404184535094077 0 0\n",
      "61 3.1404184535094077 0.0 15.0\n",
      "14 3.1404184535094077 65.0 2.25\n",
      "73 9.05524889913785 0 0\n",
      "81 18.35710511374767 45.0 8.0\n",
      "10 11.721669118593923 5.0 4.5\n",
      "29 2.840482247690528 0 0\n",
      "100 7.932349138577956 15.0 11.0\n",
      "48 10.387442356192368 50.0 4.0\n",
      "1 10.839894901576656 0 0\n",
      "95 3.2092080495726365 0 0\n",
      "71 17.923516599263525 0.0 10.0\n",
      "59 11.239250545678996 0.0 16.0\n",
      "5 4.427468568945695 0.0 11.0\n",
      "28 8.475478910832758 0 0\n",
      "56 4.28935758196377 0 0\n",
      "10 3.1404184535094077 15.0 4.5\n",
      "77 11.721669118593923 5.0 2.5\n",
      "83 1 0 0\n",
      "78 1 20.0 1.0\n",
      "23 9.561408510377229 0 0\n",
      "100 6.535380169425697 15.0 11.0\n",
      "48 10.387442356192368 5.0 4.0\n",
      "19 4.773058359766563 0 0\n",
      "91 5.304757208164739 0 0\n",
      "90 1 15.0 15.0\n",
      "89 1 13.0 9.0\n",
      "The day is over! The reward is 178.42752686415764\n",
      "A new day! Today is 2018-06-27\n",
      "91 3.151147998568417 0 0\n",
      "64 1.9952684778632919 0 0\n",
      "5 6.432100735836362 0 0\n",
      "63 6.432100735836362 0 0\n",
      "50 3.5641054203496916 0 0\n",
      "51 1 0 0\n",
      "38 4.989969523972208 0 0\n",
      "103 0 10 0\n",
      "11 2.840482247690528 5.0 4.5\n",
      "28 2.840482247690528 5.0 1.7\n",
      "83 11.95665705905574 5.0 7.0\n",
      "65 9.096194096291342 0.0 7.5\n",
      "69 9.704361340810864 0.0 1.5\n",
      "82 18.35710511374767 5.0 2.0\n",
      "76 1 0.0 1.0\n",
      "29 11.95665705905574 5.0 3.0\n",
      "17 2.840482247690528 0 0\n",
      "16 1 0 0\n",
      "58 3.1404184535094077 0.0 3.0\n",
      "9 3.1404184535094077 30.0 1.5\n",
      "96 9.206277510904412 0 0\n",
      "4 3.2092080495726365 5.0 17.0\n",
      "45 10.839894901576656 0.0 5.0\n",
      "42 1 0.0 10.0\n",
      "54 6.748117384482564 0 0\n",
      "23 3.1860278534694153 5.0 45.0\n",
      "8 7.5923188645377415 0 0\n",
      "16 6.29793434442699 0.0 45.0\n",
      "94 9.206277510904412 20.0 2.0\n",
      "85 6.6196616796660415 0.0 24.0\n",
      "94 6.6196616796660415 25.0 2.0\n",
      "74 17.923516599263525 0 0\n",
      "15 9.05524889913785 45.0 7.0\n",
      "90 5.304757208164739 35.0 15.0\n",
      "17 5.304757208164739 0 0\n",
      "87 8.541454733661212 0.0 20.0\n",
      "85 4.039609388161948 0.0 24.0\n",
      "31 11.95665705905574 40.0 2.0\n",
      "58 4.28935758196377 0 0\n",
      "64 2.0196961183755557 65.0 3.0\n",
      "38 2.8928096074512313 20.0 14.0\n",
      "49 2.464349992427426 0 0\n",
      "56 6.748117384482564 0 0\n",
      "61 1 0.0 15.0\n",
      "38 4.28935758196377 15.0 14.0\n",
      "40 1 0 0\n",
      "42 2.464349992427426 0 0\n",
      "The day is over! The reward is 258.4742629654614\n",
      "A new day! Today is 2017-05-30\n",
      "27 4.28935758196377 0 0\n",
      "27 1 0 0\n",
      "101 7.932349138577956 0 0\n",
      "60 3.644003512864643 0 0\n",
      "38 4.28935758196377 0 0\n",
      "68 6.952561299901862 0 0\n",
      "91 10.863763285716246 0 0\n",
      "52 2.2521567389083414 5.0 4.0\n",
      "28 4.989969523972208 10.0 1.7\n",
      "59 4.28935758196377 0.0 16.0\n",
      "45 6.748117384482564 0 0\n",
      "54 6.748117384482564 0 0\n",
      "101 3.644003512864643 0 0\n",
      "48 10.387442356192368 5.0 4.0\n",
      "11 4.773058359766563 10.0 4.5\n",
      "57 3.1404184535094077 0.0 15.0\n",
      "42 6.748117384482564 0.0 10.0\n",
      "5 10.839894901576656 0 0\n",
      "36 8.475478910832758 15.0 2.5\n",
      "36 1 15.0 2.5\n",
      "74 6.952561299901862 0.0 1.0\n",
      "6 15.273673239199109 0 0\n",
      "30 8.475478910832758 15.0 1.5\n",
      "55 4.28935758196377 0.0 7.0\n",
      "101 3.644003512864643 0.0 11.0\n",
      "39 7.932349138577956 35.0 4.0\n",
      "46 2.464349992427426 35.0 5.0\n",
      "55 6.748117384482564 0.0 7.0\n",
      "82 8.589987861357613 10.0 2.0\n",
      "40 11.95665705905574 0.0 10.0\n",
      "45 2.464349992427426 0.0 5.0\n",
      "24 4.643009155441806 0 0\n",
      "3 7.5923188645377415 140.0 6.0\n",
      "101 1.9192867931509592 0.0 11.0\n",
      "90 5.5167305198417225 50.0 15.0\n",
      "61 3.151147998568417 0.0 15.0\n",
      "10 3.1404184535094077 30.0 4.5\n",
      "46 4.773058359766563 20.0 5.0\n",
      "27 2.464349992427426 20.0 4.0\n",
      "91 4.544168001735182 0 0\n",
      "62 3.151147998568417 0 0\n",
      "85 8.589987861357613 0.0 24.0\n",
      "34 11.95665705905574 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 6.952561299901862 5.0 1.5\n",
      "15 9.05524889913785 50.0 7.0\n",
      "The day is over! The reward is 208.0751497875886\n",
      "A new day! Today is 2017-10-11\n",
      "89 3.151147998568417 0 0\n",
      "37 4.544168001735182 0 0\n",
      "91 4.544168001735182 0 0\n",
      "6 6.982232655600034 0 0\n",
      "66 6.432100735836362 0 0\n",
      "65 1 0 0\n",
      "13 3.327583925554344 0 0\n",
      "90 5.304757208164739 0 0\n",
      "103 0 10 0\n",
      "96 8.298973953604898 0 0\n",
      "6 3.2092080495726365 0.0 1.0\n",
      "56 4.427468568945695 0.0 3.0\n",
      "53 1 10.0 22.0\n",
      "12 3.1404184535094077 5.0 15.0\n",
      "15 1 50.0 7.0\n",
      "97 9.206277510904412 0 0\n",
      "86 3.147782119747535 55.0 7.0\n",
      "14 8.541454733661212 35.0 2.25\n",
      "102 5.735536320412861 0.0 60.0\n",
      "82 8.067995285858656 5.0 2.0\n",
      "27 11.95665705905574 15.0 4.0\n",
      "45 2.464349992427426 0.0 5.0\n",
      "62 6.748117384482564 0 0\n",
      "32 4.28935758196377 30.0 2.0\n",
      "86 9.55163482673063 60.0 7.0\n",
      "36 9.55163482673063 30.0 2.5\n",
      "62 4.28935758196377 0 0\n",
      "65 2.0196961183755557 25.0 7.5\n",
      "91 1.9952684778632919 0 0\n",
      "92 7.783068445394643 0.0 9.0\n",
      "64 8.280933018946106 50.0 3.0\n",
      "42 5.283685436233072 0.0 10.0\n",
      "51 6.472569343161453 30.0 11.0\n",
      "87 7.802225504507815 0 0\n",
      "76 4.039609388161948 0.0 1.0\n",
      "82 1 10.0 2.0\n",
      "18 11.721669118593923 0.0 15.0\n",
      "13 1 30.0 13.0\n",
      "48 4.773058359766563 15.0 4.0\n",
      "31 2.464349992427426 30.0 2.0\n",
      "The day is over! The reward is 229.5451484019802\n",
      "A new day! Today is 2018-02-04\n",
      "21 3.1860278534694153 0 0\n",
      "83 9.561408510377229 0 0\n",
      "8 8.471107496160963 0 0\n",
      "35 8.475478910832758 0 0\n",
      "90 4.544168001735182 0 0\n",
      "57 3.151147998568417 0.0 15.0\n",
      "90 3.151147998568417 5.0 15.0\n",
      "68 10.863763285716246 5.0 1.0\n",
      "46 4.491214084073219 5.0 5.0\n",
      "80 14.204159686663917 0 0\n",
      "26 3.572206570184309 0 0\n",
      "58 8.682793803844778 0 0\n",
      "73 11.239250545678996 0 0\n",
      "97 17.923516599263525 0 0\n",
      "72 17.923516599263525 5.0 2.0\n",
      "51 10.07768623029082 0 0\n",
      "1 9.234386578672103 25.0 5.0\n",
      "80 8.471107496160963 0 0\n",
      "65 9.096194096291342 20.0 7.5\n",
      "12 3.327583925554344 5.0 15.0\n",
      "16 1 0.0 45.0\n",
      "72 9.05524889913785 5.0 2.0\n",
      "70 1 5.0 9.0\n",
      "98 17.923516599263525 0 0\n",
      "23 9.535217852583342 0.0 45.0\n",
      "45 4.643009155441806 0.0 5.0\n",
      "29 2.464349992427426 10.0 3.0\n",
      "59 4.28935758196377 0.0 16.0\n",
      "18 3.1404184535094077 0.0 15.0\n",
      "30 2.840482247690528 10.0 1.5\n",
      "13 2.840482247690528 30.0 13.0\n",
      "63 3.327583925554344 10.0 14.5\n",
      "50 3.5641054203496916 0 0\n",
      "76 8.525921822877574 0 0\n",
      "23 9.561408510377229 0 0\n",
      "56 3.1860278534694153 0 0\n",
      "46 6.748117384482564 45.0 5.0\n",
      "10 4.773058359766563 10.0 4.5\n",
      "1 6.29793434442699 10.0 5.0\n",
      "46 10.839894901576656 0.0 5.0\n",
      "99 13.434202645384012 0 0\n",
      "53 6.697664654779026 15.0 22.0\n",
      "100 3.644003512864643 15.0 11.0\n",
      "99 3.0552787561825614 0 0\n",
      "74 17.923516599263525 0 0\n",
      "94 17.923516599263525 5.0 2.0\n",
      "43 13.434202645384012 0.0 5.0\n",
      "88 11.99149167799481 15.0 4.5\n",
      "The day is over! The reward is 207.66921210849245\n",
      "A new day! Today is 2017-08-02\n",
      "20 3.1860278534694153 0 0\n",
      "82 9.561408510377229 0 0\n",
      "37 11.95665705905574 0 0\n",
      "78 11.95665705905574 0 0\n",
      "34 11.95665705905574 5.0 3.0\n",
      "16 2.840482247690528 0 0\n",
      "32 2.840482247690528 5.0 2.0\n",
      "83 11.95665705905574 5.0 7.0\n",
      "14 11.721669118593923 45.0 2.25\n",
      "2 6.29793434442699 0.0 30.0\n",
      "32 8.475478910832758 10.0 2.0\n",
      "71 6.952561299901862 0.0 10.0\n",
      "1 15.273673239199109 25.0 5.0\n",
      "7 1 0 0\n",
      "20 7.5923188645377415 40.0 3.5\n",
      "77 9.561408510377229 20.0 2.5\n",
      "21 9.561408510377229 0.0 5.0\n",
      "25 1 0.0 25.0\n",
      "43 4.643009155441806 0.0 5.0\n",
      "5 10.839894901576656 0.0 11.0\n",
      "5 1 0.0 11.0\n",
      "57 4.427468568945695 0.0 15.0\n",
      "65 2.0196961183755557 15.0 7.5\n",
      "71 9.704361340810864 0.0 10.0\n",
      "44 4.491214084073219 30.0 0.73\n",
      "97 13.434202645384012 0 0\n",
      "82 6.6196616796660415 10.0 2.0\n",
      "88 4.039609388161948 45.0 4.5\n",
      "9 8.541454733661212 25.0 1.5\n",
      "32 2.840482247690528 30.0 2.0\n",
      "46 2.464349992427426 45.0 5.0\n",
      "46 1 20.0 5.0\n",
      "40 2.464349992427426 0.0 10.0\n",
      "62 4.28935758196377 0 0\n",
      "31 4.28935758196377 60.0 2.0\n",
      "55 4.28935758196377 0 0\n",
      "90 3.151147998568417 25.0 15.0\n",
      "The day is over! The reward is 231.17595425132\n",
      "A new day! Today is 2017-06-14\n",
      "35 4.28935758196377 0 0\n",
      "13 2.840482247690528 0 0\n",
      "25 3.944879147839698 0 0\n",
      "37 2.520433276982838 0 0\n",
      "38 1 0 0\n",
      "99 10.98346366328823 0 0\n",
      "42 13.434202645384012 0 0\n",
      "72 4.491214084073219 0 0\n",
      "97 17.923516599263525 0 0\n",
      "99 1 0 0\n",
      "57 6.697664654779026 0.0 15.0\n",
      "5 4.427468568945695 0 0\n",
      "82 8.471107496160963 0 0\n",
      "68 18.35710511374767 5.0 1.0\n",
      "68 1 5.0 1.0\n",
      "34 6.952561299901862 5.0 3.0\n",
      "40 1 0 0\n",
      "82 11.95665705905574 0.0 2.0\n",
      "77 1 5.0 2.5\n",
      "82 1 0.0 2.0\n",
      "65 9.096194096291342 5.0 7.5\n",
      "37 2.8928096074512313 10.0 9.5\n",
      "36 1 10.0 2.5\n",
      "64 2.8928096074512313 0 0\n",
      "61 2.0196961183755557 0.0 15.0\n",
      "75 11.239250545678996 0 0\n",
      "7 15.273673239199109 0 0\n",
      "102 7.986499393343918 0.0 60.0\n",
      "93 9.29647463266622 80.0 6.0\n",
      "0 3.2092080495726365 0.0 23.0\n",
      "0 1 0.0 23.0\n",
      "58 4.427468568945695 0 0\n",
      "63 2.0196961183755557 10.0 14.5\n",
      "46 5.283685436233072 10.0 5.0\n",
      "40 2.464349992427426 0.0 10.0\n",
      "85 11.95665705905574 0.0 24.0\n",
      "85 1 0.0 24.0\n",
      "101 6.738468253914493 0.0 11.0\n",
      "59 3.644003512864643 0.0 16.0\n",
      "68 11.239250545678996 5.0 1.0\n",
      "96 17.923516599263525 0 0\n",
      "58 6.697664654779026 0 0\n",
      "71 11.239250545678996 0.0 10.0\n",
      "16 9.05524889913785 0.0 45.0\n",
      "15 1 25.0 7.0\n",
      "86 8.541454733661212 50.0 7.0\n",
      "20 7.582261239107829 30.0 3.5\n",
      "The day is over! The reward is 194.99902951117693\n",
      "A new day! Today is 2018-08-25\n",
      "36 4.28935758196377 0 0\n",
      "27 1 0 0\n",
      "28 1 0 0\n",
      "45 2.464349992427426 0 0\n",
      "91 6.682006538126892 0 0\n",
      "42 6.682006538126892 0 0\n",
      "4 10.839894901576656 0 0\n",
      "96 3.2092080495726365 0 0\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_127217/2263628019.py\", line 4, in <module>\n",
      "    agent.learn(total_timesteps=100)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\", line 299, in learn\n",
      "    return super(PPO, self).learn(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 234, in learn\n",
      "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 175, in collect_rollouts\n",
      "    new_obs, rewards, dones, infos = env.step(clipped_actions)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 162, in step\n",
      "    return self.step_wait()\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 43, in step_wait\n",
      "    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stable_baselines3/common/monitor.py\", line 90, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/gym/wrappers/time_limit.py\", line 18, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/DS-GA 3001-007/disneyenv/disneyenv/envs/disney.py\", line 269, in step\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/DS-GA 3001-007/disneyenv/disneyenv/envs/disney.py\", line 103, in __get_observation\n",
      "    waitTime, operationStatus = self.retrieve_closest_prior_info(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/DS-GA 3001-007/disneyenv/disneyenv/envs/disney.py\", line 129, in retrieve_closest_prior_info\n",
      "    target_ilocs = target_df.index.get_indexer(input_index, method=\"ffill\")\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3973, in get_indexer\n",
      "    return self._get_indexer(target, method, limit, tolerance)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3986, in _get_indexer\n",
      "    indexer = self._get_fill_indexer(target, method, limit, tolerance)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 4083, in _get_fill_indexer\n",
      "    return engine.get_indexer_with_fill(  # type: ignore[union-attr]\n",
      "  File \"pandas/_libs/index.pyx\", line 766, in pandas._libs.index.BaseMultiIndexCodesEngine.get_indexer_with_fill\n",
      "  File \"<__array_function__ internals>\", line 180, in argsort\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 1034, in _argsort_dispatcher\n",
      "    def _argsort_dispatcher(a, axis=None, kind=None, order=None):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/gpfs/data/oermannlab/users/hz2212/.conda/envs/ds3001-007/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"disneyenv/Disney-v0\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "agent = PPO(\"MultiInputPolicy\",env,verbose=1, device=device)\n",
    "agent.learn(total_timesteps=100)\n",
    "# agent = PPO(\"MultiInputPolicy\",env,verbose=1, device=device, batch_size=1024, n_steps=1024)\n",
    "# agent.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "return_val = []\n",
    "while True:\n",
    "    action, _states = agent.predict(obs, deterministic=False)\n",
    "    #action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(\"at\", env.current_time, \"agent go to ride\", action, \"and get reward\", reward)\n",
    "    return_val += [reward]\n",
    "    \n",
    "    if done:\n",
    "        print(return_val)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
